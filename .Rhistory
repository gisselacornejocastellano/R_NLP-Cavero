knitr::opts_chunk$set(echo = TRUE)
library(rtweet)
library(tidyverse)
library(twitteR)
library(ROAuth)
library(httr)
library(tm)
library(SnowballC)
library(base64enc)
library(jsonlite)
api_key <- "K2pviSkiv84wO7Pnk7IJOcoiw"
api_secret <- "qfcfxdpvduTQz170CVgtW1krIOSIlLYLbNSlYZM5lubRxsTVeq"
access_token <- "814222538440134657-DlkjGkZqQuCng4ryXlvogShIbQB0jXd"
access_token_secret <- "4XwJH8VwpG2N9dghqHMaIpptyFTrdQNFWx31U3NYUI0Uh"
token <- create_token(
app = "R_pc2",
consumer_key = api_key,
consumer_secret = api_secret,
access_token = access_token,
access_secret = access_token_secret)
token
consumer_key = api_key
consumer_secret = api_secret
access_token = access_token
access_secret = access_token_secret
setup_twitter_oauth(consumer_key, consumer_secret, access_token, access_secret)
set_bearer()
set_bearer()
set_bearer()
set_bearer()
set_bearer()
set_bearer()
set_bearer()
tweets <-
get_all_tweets(
query = "@AlejandroCavero",
start_tweets = "2021-07-28T00:00:00Z",
end_tweets = "2020-02-07T00:00:00Z",
file = "caverotweets",
data_path = "data/",
n = 1000,
)
tweets <-
get_all_tweets(
query = "@AlejandroCavero",
start_tweets = "2021-07-28T00:00:00Z",
end_tweets = "2020-02-07T00:00:00Z",
file = "caverotweets",
data_path = "data/",
n = 1000,
)
knitr::opts_chunk$set(echo = TRUE)
library(rtweet)
library(tidyverse)
library(twitteR)
library(ROAuth)
library(httr)
library(tm)
library(SnowballC)
library(base64enc)
library(jsonlite)
bearer_token <- Sys.getenv("AAAAAAAAAAAAAAAAAAAAABbTYwEAAAAArNICJ5uq1dwShJnC1tkwPH6Fr0c%3DbBpY2uchEP9zcUXIAPs7QAUvbXmZyEds5akiXnbIxjyAEBIGoZ")
headers <- c(`Authorization` = sprintf('Bearer %s', bearer_token))
params <- list(`user.fields` = 'text')
handle <- readline('@AlejandroCavero')
rm(list=ls())
knitr::opts_chunk$set(echo = TRUE)
library(rtweet)
library(tidyverse)
library(twitteR)
library(ROAuth)
library(httr)
library(tm)
library(SnowballC)
api_key <- "K2pviSkiv84wO7Pnk7IJOcoiw"
api_secret <- "qfcfxdpvduTQz170CVgtW1krIOSIlLYLbNSlYZM5lubRxsTVeq"
access_token <- "814222538440134657-DlkjGkZqQuCng4ryXlvogShIbQB0jXd"
access_token_secret <- "4XwJH8VwpG2N9dghqHMaIpptyFTrdQNFWx31U3NYUI0Uh"
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
Cavero <- get_timeline("@AlejandroCavero", 1000)
Cavero[1,5]
View(Cavero)
glimpe(Cavero)
glimpse(Cavero)
write.csv(Cavero, "C:\Users\jecas\Documents\GitHub\NLP_AleCav", row.names=FALSE)
write.csv(Cavero, "C:/Users/jecas/Documents/GitHub/NLP_AleCav", row.names=FALSE)
write.csv(Cavero, "C:/Users/jecas/Documents/GitHub/NLP_AleCav", row.names=FALSE)
write.csv(Cavero, "C:\\Users\\jecas\\Documents\\GitHub/NLP_AleCav", row.names=FALSE)
write.csv(Cavero, "C:/Users/jecas/", row.names=FALSE)
write.csv(Cavero, "C:\\Users\\jecas\\Documents\\GitHub\\NLP_AleCav\\Cavero.csv", row.names=FALSE)
write.csv(Cavero, "C:\\Users\\jecas\\Documents\\GitHub\\NLP_AleCav\\Cavero.csv", row.names=FALSE)
Cavero <- apply(Cavero,2,as.character)
write.csv(Cavero, "C:\\Users\\jecas\\Documents\\GitHub\\NLP_AleCav\\Cavero.csv", row.names=FALSE)
View(Cavero)
source("~/001 Personal/R_intermedio/08 NLP/NLP (1).R")
knitr::opts_chunk$set(echo = TRUE)
library(rtweet)
library(tidyverse)
library(twitteR)
library(ROAuth)
library(httr)
library(tm)
library(SnowballC)
library(rio)
library(wordcloud)
library(SentimentAnalysis)
Github <- "https://github.com/gisselacornejocastellano/R_NLP-Cavero/raw/main/Cavero_Tweets.csv"
Cavero_All_Tweets <- import(Github, encoding ="UTF-8")
max(Cavero_All_Tweets$created_at); min(Cavero_All_Tweets$created_at)
head(Cavero_All_Tweets$text)
Cavero_RT_Deleted <- Cavero_All_Tweets[Cavero_All_Tweets$is_retweet == 'FALSE',]
Cavero_Text <- Cavero_RT_Deleted$text
Corpus <- Corpus(VectorSource(Cavero_Text))
length(Cavero_Text)
content(Corpus[1])
Corpus <- tm_map(Corpus,content_transformer(tolower))
content(Corpus[1])
Quitar_URL <- function(x) gsub("http[^[:space:]]*", "", x)
Corpus <- tm_map(Corpus, content_transformer(Quitar_URL))
content(Corpus[1])
Quitar_Tilde <- function(x) chartr('áéíóú','aeiou',x)
Corpus <- tm_map(Corpus, Quitar_Tilde)
content(Corpus[1])
Quitar_Interrogacion1 <- function(x) chartr('?',' ',x)
Quitar_Interrogacion2 <- function(x) chartr('¿',' ',x)
Corpus <- tm_map(Corpus, Quitar_Interrogacion1)
Corpus <- tm_map(Corpus, Quitar_Interrogacion2)
content(Corpus[1])
Quitar_Exclamacion1 <- function(x) chartr('¡',' ',x)
Quitar_Exclamacion2 <- function(x) chartr('!',' ',x)
Corpus <- tm_map(Corpus, Quitar_Exclamacion1)
Corpus <- tm_map(Corpus, Quitar_Exclamacion2)
content(Corpus[1])
content(Corpus[91])
Quitar_Usuarios <- function(x) gsub("@\\w+", "", x)
Corpus <- tm_map(Corpus, Quitar_Usuarios)
content(Corpus[91])
content(Corpus[1])
Corpus <- tm_map(Corpus, removeNumbers)
content(Corpus[1])
content(Corpus[3])
Corpus <- tm_map(Corpus, removePunctuation)
content(Corpus[3])
content(Corpus[1])
Corpus <- tm_map(Corpus, removeWords,c(stopwords("spanish")))
content(Corpus[1])
Corpus <- tm_map(Corpus, removeWords,c("mas", "asi", "ser", "aqui", ""))
content(Corpus[1])
Corpus <- tm_map(Corpus, stripWhitespace)
content(Corpus[1])
Terminos <- TermDocumentMatrix(Corpus)
Terminos
inspect(Terminos)
findFreqTerms(Terminos,lowfreq = 10) # al menos 10 veces
Matriz <- as.matrix(Terminos)
head(Matriz)
Decreciente <- sort(rowSums(Matriz),decreasing=TRUE)
head(Decreciente)
Cavero_DF <- data.frame(Palabra = names(Decreciente), freq=Decreciente)
Cavero_DF
Cavero_DF2 <- Cavero_DF
hist(Cavero_DF2$freq)
Cavero_DF2 <- subset(Cavero_DF2, Cavero_DF2$freq >= 10)
Cavero_DF2
ggplot(Cavero_DF2, aes( x= Palabra, y=freq )) + geom_bar(stat="identity") +
xlab("Términos") + ylab("Frecuencia") + coord_flip() +
theme(axis.text=element_text(size=7))
barplot(Cavero_DF2[1:20,]$freq, las = 2, names.arg = Cavero_DF2[1:20,]$Palabra,
col ="brown", main ="Top 5 palabras más frecuentes",
ylab = "Palabras más frecuentes")
#head(Cavero_DF)
#Conteo_Palabras <- data.frame(freq = apply(Palabra,1,sum))
#head(Conteo_Palabras)
wordcloud(Cavero_DF$Palabra, Cavero_DF$freq, random.order=FALSE, min.freq=2, colors=brewer.pal(8, "Dark2"))
findAssocs(Terminos, c("peru"), c(0.30))
findAssocs(Terminos, c("libertad"), c(0.30))
findAssocs(Terminos, c("congreso"), c(0.30))
Cluster <- removeSparseTerms(Terminos, sparse = 0.96)
m2 <- as.matrix(Cluster)
distMatrix <- dist(scale(m2))
fit <- hclust(distMatrix, method = "ward.D")
plot(fit)
rect.hclust(fit, k = 5)
Sentimientos <- analyzeSentiment(Cavero_Text,language = "spanish")
Sentimientos_final <- data.frame(Cavero_Text,
sentiment = convertToDirection(Sentimientos$SentimentGI))
table(Sentimientos_final$sentiment)
Sentimientos_final$score <- 0
Sentimientos_final$score[Sentimientos_final$sentiment == "positive"] <- 1
Sentimientos_final$score[Sentimientos_final$sentiment == "negative"] <- -1
head(Sentimientos_final)
table(Sentimientos_final$score)
#head(Cavero_DF)
#Conteo_Palabras <- data.frame(freq = apply(Palabra,1,sum))
#head(Conteo_Palabras)
wordcloud(Cavero_DF$Palabra,
Cavero_DF$freq,
random.order=FALSE,
min.freq=2,
colors=brewer.pal(8, "Dark2"))
View(Sentimientos)
#fetch sentiment words from texts
Sentiment <- get_nrc_sentiment(text)
?get_nrc_sentiment
??get_nrc_sentiment
install.packages("syuzhet")
library(rtweet)
library(tidyverse)
library(twitteR)
library(ROAuth)
library(httr)
library(tm)
library(SnowballC)
library(rio)
library(wordcloud)
library(SentimentAnalysis)
library(syuzhet)
#fetch sentiment words from texts
Sentiment <- get_nrc_sentiment(text)
#fetch sentiment words from texts
Sentiment <- get_nrc_sentiment(Cavero_Text)
head(Sentiment)
text <- cbind(text,Sentiment)
View(Terminos)
View(Sentimientos)
View(Sentimientos_final)
View(Sentiment)
View(Sentimientos_final)
View(Sentimientos)
View(Sentiment)
#fetch sentiment words from texts
Otros_Sentimientos <- get_nrc_sentiment(Cavero_Text)
head(Sentiment)
text <- cbind(Cavero_Text,Otros_Sentimientos)
View(text)
View(Sentimientos_final)
#fetch sentiment words from texts
lang <- "spanish"
Otros_Sentimientos <- get_nrc_sentiment(Cavero_Text, language=lang)
head(Sentiment)
Sentimientos_Agregados <- cbind(Cavero_Text,Otros_Sentimientos)
method <- "nrc"
lang <- "spanish"
my_text_values <- get_sentiment(Cavero_Text, method=method, language=lang)
my_text_values[1:10]
??get_sentiment
?get_sentiment
method <- "nrc"
lang <- "spanish"
my_text_values <- get_sentiment(Cavero_Text, method = "stanford", language = "spanish")
install.packages("coreNLP")
library(rtweet)
library(tidyverse)
library(twitteR)
library(ROAuth)
library(httr)
library(tm)
library(SnowballC)
library(rio)
library(wordcloud)
library(SentimentAnalysis)
library(syuzhet)
library(coreNLP)
library(rtweet)
library(tidyverse)
library(twitteR)
library(ROAuth)
library(httr)
library(tm)
library(SnowballC)
library(rio)
library(wordcloud)
library(SentimentAnalysis)
library(syuzhet)
library(coreNLP)
install.packages("coreNLP")
method <- "nrc"
lang <- "spanish"
my_text_values <- get_sentiment(Cavero_Text, method = "stanford", language = "spanish")
install.packages("lda")
library(rtweet)
library(tidyverse)
library(twitteR)
library(ROAuth)
library(httr)
library(tm)
library(SnowballC)
library(rio)
library(wordcloud)
library(SentimentAnalysis)
library(syuzhet)
library(coreNLP)
if(Sys.getenv("JAVA_HOME")!=""){
Sys.setenv(JAVA_HOME="")
}
library(rJava)
install.packages("rJava")
if(Sys.getenv("JAVA_HOME")!=""){
Sys.setenv(JAVA_HOME="")
}
library(rJava)
if(Sys.getenv("JAVA_HOME")!=""){
Sys.setenv(JAVA_HOME="")
}
library(rJava)
method <- "nrc"
lang <- "spanish"
my_text_values <- get_sentiment(Cavero_Text, method = "stanford", language = "spanish")
library(rtweet)
library(tidyverse)
library(twitteR)
library(ROAuth)
library(httr)
library(tm)
library(SnowballC)
library(rio)
library(wordcloud)
library(SentimentAnalysis)
library(syuzhet)
library(rJava)
install.packages("rJava")
library(rtweet)
library(tidyverse)
library(twitteR)
library(ROAuth)
library(httr)
library(tm)
library(SnowballC)
library(rio)
library(wordcloud)
library(SentimentAnalysis)
library(syuzhet)
library(rJava)
install.packages("udpipe")
library(udpipe)
library(rtweet)
library(tidyverse)
library(twitteR)
library(ROAuth)
library(httr)
library(tm)
library(SnowballC)
library(rio)
library(wordcloud)
library(SentimentAnalysis)
library(syuzhet)
library(coreNLP)
library(rtweet)
library(tidyverse)
library(twitteR)
library(ROAuth)
library(httr)
library(tm)
library(SnowballC)
library(rio)
library(wordcloud)
library(SentimentAnalysis)
library(syuzhet)
library(lda)
library(udpipe)
corpusLDA <- lexicalize(Corpus )
ldaModel=lda.collapsed.gibbs.sampler(corpusLDA$documents,K=5,vocab=Corpus$vocab,burnin=9999,num.iterations=1000,alpha=0.7,eta=0.1)
corpusLDA <- lexicalize(Corpus)
ldaModel=lda.collapsed.gibbs.sampler(corpusLDA$documents,K=5,vocab=Corpus$vocab,burnin=9999,num.iterations=1000,alpha=0.7,eta=0.1)
