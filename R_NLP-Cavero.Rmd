---
title: "Análisis de la cuenta de Alejando Cavero"
author: "Gissela_Cornejo_Castellano"
date: "8/2/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Este trabajo analiza los últimos 1000 tweets del congresista Alejando Cavero (@AlejandroCavero) al 08 de febrero de 2022, 9.30 a.m.

```{r Librerías}
library(rtweet)
library(tidyverse)
library(twitteR)
library(ROAuth)
library(httr)
library(tm)
library(SnowballC)
library(rio)
```

# 1. Conseguir la data

## 1.1 API de Twitter y establecer conexión

En aras de no usar repetidas veces mis credenciales, una vez extraída la data la exporté como csv. Por esa razón he colocado los siguientes chunks como comentario y he borrado mis claves.
```{#r}
api_key <- ""
api_secret <- ""
access_token <- ""
access_token_secret <- ""
```

```{#r}
setup_twitter_oauth(api_key,api_secret,access_token,access_token_secret)
```

## 1.2 Extraer tweets
```{#r}
Cavero <- get_timeline("@AlejandroCavero", 1000)
```

```{#r}
Cavero2 <- tweets_data(Cavero)
head(Cavero2)
```

## 1.3 Exportar la base de datos a csv para subirlas a Github.

```{#r}
export(Cavero2,"Cavero_Tweets.csv",row.names = F)
```

## 1.3 Importar base desde Github, para la reproducibilidad de este Rmd.
```{r}
Github <- "https://github.com/gisselacornejocastellano/R_NLP-Cavero/raw/main/Cavero_Tweets.csv"

Cavero_All_Tweets <- import(Github, encoding ="UTF-8")
```


# 2. Preprocesamiento
```{r}
max(Cavero_All_Tweets$created_at); min(Cavero_All_Tweets$created_at)
head(Cavero_All_Tweets$text)
```
## 2.1 Creación de corpus
```{r}
Cavero_RT_Deleted <- Cavero_All_Tweets[Cavero_All_Tweets$is_retweet == 'FALSE',]

Cavero_Text <- Cavero_RT_Deleted$text
```

```{r}
Corpus <- Corpus(VectorSource(Cavero_Text))
length(Cavero_Text)
content(Corpus[1])
```
## 2.2 Transformación de texto
```{r Minúsculas}
content(Corpus[1])
Corpus <- tm_map(Corpus,content_transformer(tolower)) 
content(Corpus[1])
```

```{r Eliminar links}
content(Corpus[1])
Quitar_URL <- function(x) gsub("http[^[:space:]]*", "", x)
Corpus <- tm_map(Corpus, content_transformer(Quitar_URL))
content(Corpus[1])
```
```{r Eliminar tildes}
content(Corpus[1])
Quitar_Tilde <- function(x) chartr('áéíóú','aeiou',x)
Corpus <- tm_map(Corpus, Quitar_Tilde)
content(Corpus[1])
```
```{r Eliminar '?' y '¿'}
content(Corpus[1])
Quitar_Interrogacion1 <- function(x) chartr('?',' ',x)
Quitar_Interrogacion2 <- function(x) chartr('¿',' ',x)
Corpus <- tm_map(Corpus, Quitar_Interrogacion1)
Corpus <- tm_map(Corpus, Quitar_Interrogacion2)
content(Corpus[1])
```
```{r Eliminar '¡' y '!'}
content(Corpus[1])
Quitar_Exclamacion1 <- function(x) chartr('¡',' ',x)
Quitar_Exclamacion2 <- function(x) chartr('!',' ',x)
Corpus <- tm_map(Corpus, Quitar_Exclamacion1)
Corpus <- tm_map(Corpus, Quitar_Exclamacion2)
content(Corpus[1])
```

```{r Eliminar handles}
content(Corpus[91])
Quitar_Usuarios <- function(x) gsub("@\\w+", "", x)
Corpus <- tm_map(Corpus, Quitar_Usuarios)
content(Corpus[91])
```

```{r Eliminar números}
content(Corpus[1])
Corpus <- tm_map(Corpus, removeNumbers)
content(Corpus[1])
```

```{r Quitar puntuación}
content(Corpus[3])
Corpus <- tm_map(Corpus, removePunctuation)
content(Corpus[3])
```

## 2.3 Remover Stopwords

```{r}
content(Corpus[1])
Corpus <- tm_map(Corpus, removeWords,c(stopwords("spanish")))
content(Corpus[1])
```
## Remover espacios en blanco excesivos
```{r}
content(Corpus[1])
Corpus <- tm_map(Corpus, stripWhitespace)
content(Corpus[1])
```

